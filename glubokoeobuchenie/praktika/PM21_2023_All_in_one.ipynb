{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f84de2d-6cb6-4f06-9a2f-52f368330de9",
   "metadata": {},
   "source": [
    "Bilet 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a740b7-49f1-4773-95bb-2267881e9da8",
   "metadata": {},
   "source": [
    "2 вопрос (20 баллов)\n",
    "Задать два двумерных тензора ar1 и ar2 размерности (4, 7), \n",
    "состоящих из случайных целых чисел в пределах \n",
    "от 0 до 10. Построить двумерный тензор размерности (4, 7), \n",
    "каждый элемент которого представляет собой \n",
    "максимум из двух значений, находящихся на аналогичной позиции в тензорах ar1, ar2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b16362f-eac1-4944-abaa-7474ff857a19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 8,  8,  5,  6,  0,  8,  5],\n",
       "         [ 0,  2,  1,  8, 10,  3,  4],\n",
       "         [ 9,  5,  2,  9,  7,  2,  6],\n",
       "         [ 2, 10,  6,  7,  4,  7, 10]]),\n",
       " tensor([[ 6,  3, 10, 10,  5,  9,  6],\n",
       "         [ 9,  5,  2,  6,  0,  4,  0],\n",
       "         [ 7,  5,  2,  1,  8,  2,  7],\n",
       "         [ 7,  9,  6,  8,  9,  6,  8]]),\n",
       " tensor([[ 8,  8, 10, 10,  5,  9,  6],\n",
       "         [ 9,  5,  2,  8, 10,  4,  4],\n",
       "         [ 9,  5,  2,  9,  8,  2,  7],\n",
       "         [ 7, 10,  6,  8,  9,  7, 10]]))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "ar1 = torch.randint(0, 11, (4, 7))\n",
    "ar2 = torch.randint(0, 11, (4, 7))\n",
    "\n",
    "max_tensor = torch.max(ar1, ar2)\n",
    "\n",
    "ar1, ar2, max_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c995c0-4775-4d1f-8fef-45f9cc1aba15",
   "metadata": {},
   "source": [
    "3 вопрос (20 баллов) \n",
    "Реализовать методы forward и backward в полносвязном слое. Входные данные обязательно должны быть в \n",
    "виде батчей (то есть кол-во измерений в inputs 2). Нельзя использовать готовую реализацию обратного \n",
    "распространения из PyTorch.\n",
    "Шаблон кода, который можно использовать за основу: https://pastebin.com/Ugvjf6PA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ce09a6a-fcdf-40e6-8ba1-0d01a15790d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.0247, -0.0049],\n",
       "         [-0.0150, -0.0095],\n",
       "         [ 0.0056,  0.0116],\n",
       "         [ 0.0169,  0.0013]]),\n",
       " tensor([[-0.2898, -0.0815],\n",
       "         [-1.9656, -1.5472],\n",
       "         [ 1.7130,  1.4928]]),\n",
       " tensor([0.5855, 1.1042]),\n",
       " tensor([[-0.0140, -0.0006, -0.0159],\n",
       "         [ 0.0017,  0.0016, -0.0033],\n",
       "         [ 0.0105,  0.0042, -0.0011],\n",
       "         [ 0.0169, -0.0041,  0.0356]]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from typing import Optional\n",
    "\n",
    "class Linear:\n",
    "    def __init__(self, n_inputs: int, n_neurons: int):\n",
    "        self.weights = torch.randn(n_inputs, n_neurons) * 0.01\n",
    "        self.biases = torch.randn(n_neurons) * 0.01\n",
    "        self.inputs: Optional[torch.Tensor] = None\n",
    "\n",
    "    def forward(self, inputs: torch.Tensor) -> torch.Tensor:\n",
    "        assert inputs.ndim == 2\n",
    "        self.inputs = inputs\n",
    "        return torch.mm(inputs, self.weights) + self.biases\n",
    "\n",
    "    def backward(self, dvalue: torch.Tensor) -> None:\n",
    "        self.dweights = torch.mm(self.inputs.T, dvalue)\n",
    "        self.dbiases = dvalue.sum(axis=0)\n",
    "\n",
    "        self.dinput = torch.mm(dvalue, self.weights.T)\n",
    "\n",
    "linear_layer = Linear(n_inputs=3, n_neurons=2)\n",
    "\n",
    "inputs = torch.randn(4, 3)\n",
    "\n",
    "output = linear_layer.forward(inputs)\n",
    "\n",
    "dvalue = torch.randn(4, 2)\n",
    "\n",
    "linear_layer.backward(dvalue)\n",
    "\n",
    "output, linear_layer.dweights, linear_layer.dbiases, linear_layer.dinput"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2488eda3-f514-4860-b9e8-411f14a8eca6",
   "metadata": {},
   "source": [
    "Bilet 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253610b2-7285-4403-947d-9dedefc5fbdf",
   "metadata": {},
   "source": [
    "2 вопрос (20 баллов)\n",
    "Используя операции над матрицами и векторами из библиотеки PyTorch реализовать полносвязный слой с \n",
    "заданными весами weights и biases. Прогнать вектор inputs через слой и вывести результат. Входные данные \n",
    "обязательно должны быть в виде батчей (то есть кол-во измерений в inputs 2). Нельзя использовать готовые \n",
    "слои из PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4baea00a-b245-40de-a5af-fff57dbf9f98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9000, 1.6000, 2.3000],\n",
       "        [1.9000, 3.4000, 4.9000]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "weights = torch.tensor([[0.2, 0.3], [0.4, 0.5], [0.6, 0.7]])\n",
    "biases = torch.tensor([0.1, 0.2, 0.3])\n",
    "\n",
    "inputs = torch.tensor([[1.0, 2.0], [3.0, 4.0]])\n",
    "\n",
    "def fully_connected_layer(inputs, weights, biases):\n",
    "    return torch.matmul(inputs, weights.T) + biases\n",
    "\n",
    "output = fully_connected_layer(inputs, weights, biases)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5270db8a-5d05-4ddc-b10d-be3039f23444",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-7.1360,  1.1695,  4.5237],\n",
       "        [ 3.6598,  3.1153, 10.7741],\n",
       "        [-2.5346, -5.4452, -1.2682]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#альтернатива\n",
    "\n",
    "import torch\n",
    "\n",
    "class Linear:\n",
    "    def __init__(self, n_features, n_neurons):\n",
    "        self.weights = torch.randn((n_features, n_neurons))\n",
    "        self.biases = torch.randn(n_neurons)\n",
    "  \n",
    "    def forward(self, inputs):\n",
    "        return (inputs @ self.weights) + self.biases  # torch.matmul(inputs, self.weights) + self.biases\n",
    "\n",
    "weights = torch.randn(4, 3)\n",
    "weights\n",
    "\n",
    "inputs = torch.tensor([[1, 2, 3, 2.5], \n",
    "                       [2, 5, -1, 2], \n",
    "                       [-1.5, 2.7, 3.3, -0.8]])\n",
    "inputs @ weights\n",
    "\n",
    "linear = Linear(n_features = 4, n_neurons = 3)\n",
    "linear.forward(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f392a72-1c30-4daa-b9b3-35962fbf18e2",
   "metadata": {},
   "source": [
    "3 вопрос (20 баллов) \n",
    "При помощи готовых слоев PyTorch реализуйте класс модели, который:\n",
    "содержит слои Conv2d, Linear;\n",
    "может принимать изображение с 3 каналами;\n",
    "возвращает вектор из 10 чисел для каждого фото;\n",
    "числа в этом векторе принимают значения от 0 до +бесконечности. \n",
    "Кол-во слоев, каналов внутри сверток и т.д. можете выбирать сами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "162e4836-de34-45c0-8587-b3416e7e9283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0285, -0.0446,  0.0640, -0.0069,  0.0315,  0.0365, -0.0111,  0.0319,\n",
       "          0.0200, -0.0381],\n",
       "        [-0.0510, -0.0524,  0.0481, -0.0273,  0.0288,  0.0438,  0.0147,  0.0179,\n",
       "         -0.0061, -0.0548],\n",
       "        [-0.0496, -0.0536,  0.0642, -0.0191,  0.0195,  0.0371, -0.0086,  0.0428,\n",
       "          0.0285, -0.0601],\n",
       "        [-0.0492, -0.0537,  0.0819, -0.0438,  0.0263,  0.0718, -0.0020,  0.0072,\n",
       "         -0.0165, -0.0758]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "\n",
    "class CIFAR10CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CIFAR10CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.fc1 = nn.Linear(64 * 8 * 8, 512)\n",
    "        self.fc2 = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64 * 8 * 8)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=os.cpu_count())\n",
    "\n",
    "net = CIFAR10CNN()\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "net.to(device)\n",
    "\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "images = images.to(device)\n",
    "\n",
    "outputs = net(images)\n",
    "outputs.detach().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c203573-b302-470e-b76b-6951f8e20b60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
